## 18.03
* Сделал препроцессирование данных (формирование словарей, выделенение out of vocabulary слов и пр.).
* Разобрался со схемой работы сверточного слоя.
* Наметил общую структуру baseline модели, реализовал инициализацию слоев и весов.
* Реализовал потенциальное решение проблемы OOV слов (но скорее всего откажусь от него в пользу случайной инициализации и дообучения).

## 22.03
* Завершил общую структуру baseline модели, реализовал циклы обучения и оценки.
* Убедился в работоспособности модели, обучив ее на 1000 примерах из train датасета.
  
  ![Alt text](old_plots/mini_full.png?raw=true "Title")

Полностью модель выучить примеры не смогла, достигнув F1 порядка 0.99 на 80ой эпохе, что может быть плохим знаком.

* Далее попробовал обучить модель на полном датасете и получил результаты, которые затрудняюсь объяснить:
  
  ![Alt text](old_plots/train2.png?raw=true "Title")
  ![Alt text](old_plots/valid2.png?raw=true "Title")
  
Модель достигает на первой эпохе F1 меры 0.83 и перестает обучаться. Сначала я предположил, что проблема в слишком маленьком lr или в слишком сильной регуляризации dropout'ом, но эксперименты с увеличением первого и уменьшением второго только ухудшили результаты. Затем я предположил, что модель полностью обучилась к концу первой эпохи, а переобучаться ей мешал сильный dropout. Но в таком случае нужна модель много меньшей мощности, из чего я выдвинул предположение, что какие-то слои почему-то не работают. По аналогии с FFNN без добавления нелинейных активаций. Это бы объяснило, почему модель так и не смогла выучить 1000 примеров.
  
Тогда я убрал сначала CNN слой и обучил оставшуюся модель на тех же 1000 примерах из train выборки:
  
 ![Alt text](old_plots/mini_cnn.png?raw=true "Title")
 
А затем попробовал убрать bLTSM слой:
 
 ![Alt text](old_plots/mini_lstm.png?raw=true "Title")
 
И вообще убрать все, кроме CRF слоя и эмбеддингов слов:
 
 ![Alt text](old_plots/mini_crf.png?raw=true "Title")
 
Конечные результаты:
 
| Модель      | F1     |
| ------      | ------ |
| CNNbLSTMCRF | 0.9887 |
| bLSTMCRF    | 0.9867 |
| CNNCRF      | 0.9091 |
| CRF         | 0.9265 |

Не уверен, что из этого можно делать какие-либо выводы, но факт того, что при добавлении к CRF CNN слоя F1 мера падает почти на 0.02, настораживает. Возможно, проблема в нем.

## 25.03
* Поменял метрику оценки на не учитывающую значение F1 меры для класса 'O'.
  
  Значения новой F1 меры и функции потерь в процессе обучения:
  
  ![Alt text](old_plots/train_nm.png?raw=true "Title")
  
Как и ожидалось, модель за первую эпоху учится всегда ставить метку 'O' (recall этого класса равен 1.0). Аналогичное плато можно видеть и при обучении на меньших датасетах:
  
  1000 примеров
  
  ![Alt text](old_plots/mini_high_lr_high_decay.png?raw=true "Title")
  
  5000 примеров
  
  ![Alt text](old_plots/mini_5k_a_lr005.png?raw=true "Title")
  
В ходе экспериментов с меньшими датасетами установил, что размер плато зависит как от размера выборки, так и от гиперпараметров, влияющих на learning rate. Возможно, существует такая комбинация гиперпараметров, при которой модель выйдет из плато в разумные сроки.
  
## 29.03
* Поменял метрику на оценивающую правильность определения именованных сущностей, а не выбора класса метки.
* Изменил процесс разбиение по батчам, чтобы модель обучалась на цельных предложениях.
* С помощью раннего останова добился качества, сравнимого с заявленным в статье:

Значение функции потерь на обучающем и валидационном наборах после 5-ти эпох обучения:

![Alt text](plots/loss_5_best.png?raw=true "Title")

F1 мера на обучающем и валидационном наборах после 5-ти эпох обучения:

![Alt text](plots/f1_5_best.png?raw=true "Title")

Конечные результаты:

| Набор | F1     |
| ----- | ------ |
| Train | 0.9962 |
| Valid | 0.9474 |
| Test  | 0.9092 |

## 01.04
* Разработал критерии останова обучения модели на текущем датасете и останова цикла активного обучения в целом.
* Реализовал цикл активного обучения.
* Для будущего сравнения с методом N-Best Sequence Entropy построил зависимость качества модели от размера датасета с рандомным сэмплингом новых примеров:

Зависимость значения функции потерь лучшей модели, которую можно получить на датасете, от размера датасета:

![Alt text](plots/active_loss_i100_s100_no_entropy.png?raw=true "Title")

Зависимость значения F1 меры лучшей модели, которую можно получить на датасете, от размера датасета:

![Alt text](plots/active_f1_i100_s100_no_entropy.png?raw=true "Title")

## 05.04
* Реализовал оценку энтропии методом N-Best Sequence Entropy для "неразмеченного корпуса".

При обучении модели на начальных корпусах разного размера получаются следующие распределения значений энтропии предложений в зависимости от длины предложения:

1. 100 примеров (качество модели ~0.50 F1)

![Alt text](plots/entropy_100.png?raw=true "Title")

2. 500 примеров (качество модели ~0.80 F1)

![Alt text](plots/entropy_500.png?raw=true "Title")

3. 1500 примеров (качество модели ~0.85 F1)

![Alt text](plots/entropy_1500.png?raw=true "Title")

  Хорошо видна обратная зависимость значений энтропии в среднем от качества модели. Также можно отметить, что длинные предложения в среднем (в особенности для лучше обученной модели) имеют большую энтропию.

* Поэкспериментировал с начальным размером обучающего набора.

Сравнение методов сэмлирования N-Best Sequence Entropy (NSE) и рандомного для разных начальных размеров обучающего набора:

1. 100 примеров

![Alt text](plots/active_comp_f1_i100_s100.png?raw=true "Title")

![Alt text](plots/active_comp_loss_i100_s100.png?raw=true "Title")

2. 500 примеров

![Alt text](plots/active_comp_f1_i500_s100.png?raw=true "Title")

![Alt text](plots/active_comp_loss_i500_s100.png?raw=true "Title")

Сэмплирование новых примеров с учетом энтропии дает стабильный прирост в качестве модели на любом (протестированном) размере обучающего набора. Однако оно и увеличивает сложность разметки в силу того, что в среднем у длинных предложений энтропия выше. В моих экспериментах средняя длина сэмплированных предложений увеличивалась на 35% при использовании NSE в сравнении с рандомным сэмплированием.

* Поэкспериментировал с зависимостью количества новых примеров на каждом шаге активного обучения от размера текущего обучающего набора.

Идея поставить количество новых слов в зависимость от размера датасета имеет корни в следующем факте: модель способна адекватно оценивать информативность примера только предварительно обучившись (необученнная модель имеет большую энтропию на практически всех примерах). Значит, нужно на первых шагах активного обучения сэмплировать маленькими порциями (чтобы получать как можно меньше неинформативных примеров) и увеличивать по мере обучения.

Результаты для сэмплирования 0.13 от текущего обучающего набора на каждом шаге обучения:

![Alt text](plots/active_f1_i100_coef.png?raw=true "Title")

![Alt text](plots/active_loss_i100_coef.png?raw=true "Title")

| Набор | F1     |
| ----- | ------ |
| Train | 0.9787 |
| Valid | 0.9436 |
| Test  | 0.9066 |

Как приятный побочный эффект - модель обучилась за 7 часов вместо 10 как было с константным количеством сэмплирования.

# Вывод

Сэмплирование с учетом энтропии новых примеров хоть и увеличивает сложность разметки этих примеров, выбирая в среднем более длинные предложения, но дает заметный прирост в качестве модели, позволяющий добиться (при подборе гиперпараметров активного обучения) качества модели, обученной на значительно меньшем объеме размеченных данных, сравнимого с качеством модели, обученной на полностью размеченном датасете.
